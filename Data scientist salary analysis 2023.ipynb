{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee32f97d-d5a5-4f1e-871e-2f92223088eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "spark = SparkSession.builder\\\n",
    "  .master(\"local\").config('spark.executor.instances', 8)\\\n",
    "  .appName(\"Data sicnece salary analysis\")\\\n",
    "  .getOrCreate()\n",
    "\n",
    "storage_account_name = \"*****\"\n",
    "\n",
    "# Azure Storage Account Key\n",
    "storage_account_key = \"\"\n",
    "\n",
    "# Azure Storage Account Source Container\n",
    "container = \"data\"\n",
    "\n",
    "# Set the configuration details to read/write\n",
    "spark.conf.set(\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account_name), storage_account_key)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b24a8ddf-f866-49b5-a1ea-e51e1a454a89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "file_location = \"wasb://data@rajdep561.blob.core.windows.net/ds_salaries.csv\"\n",
    "df = spark.read.format('csv').option('header','true').load(file_location)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42535367-4f4d-47c0-8d17-ea2e08456ca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('salary',df['salary'].cast('int'))\\\n",
    ".withColumn('salary_in_usd',df['salary_in_usd'].cast('int'))\\\n",
    ".withColumn('remote_ratio',df['remote_ratio'].cast('int'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3faa51f3-f297-4325-b67f-53a6527bec2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill(value='-',subset=[\"work_year\",\"experience_level\",\"employment_type\"\\\n",
    "                                ,\"job_title\",\"salary_currency\",\"employee_residence\",\"company_location\",\"company_size\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c36196-03ee-4a1b-86e5-46e32b613d70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiences = df.select('experience_level').distinct().toPandas().values\n",
    "exper_d = {}\n",
    "for i,k in enumerate(experiences):\n",
    "    exper_d[k[0]] =i\n",
    "exper_udf = udf(lambda x:exper_d[x])\n",
    "\n",
    "\n",
    "employment_type = df.select('employment_type').distinct().toPandas().values\n",
    "emp_type = {}\n",
    "for i,k in enumerate(employment_type):\n",
    "    emp_type[k[0]] =i\n",
    "emp_udf = udf(lambda x:emp_type[x])\n",
    "\n",
    "\n",
    "job_title = df.select('job_title').distinct().toPandas().values\n",
    "jb_title = {}\n",
    "for i,k in enumerate(job_title):\n",
    "    jb_title[k[0]] =i\n",
    "jb_udf = udf(lambda x:jb_title[x])\n",
    "    \n",
    "\n",
    "salary_curr = df.select('salary_currency').distinct().toPandas().values\n",
    "sal_cur = {}\n",
    "for i,k in enumerate(salary_curr):\n",
    "    sal_cur[k[0]]=i\n",
    "sal_udf = udf(lambda x:sal_cur[x])\n",
    "    \n",
    "    \n",
    "location = df.select('company_location').distinct().toPandas().values\n",
    "cmp_local = {}\n",
    "for i,k in enumerate(location):\n",
    "    cmp_local[k[0]] = i\n",
    "local_udf = udf(lambda x: cmp_local[x])\n",
    "\n",
    "\n",
    "emp_location = df.select('employee_residence').distinct().toPandas().values\n",
    "emp_local = {}\n",
    "for i,k in enumerate(emp_location):\n",
    "    emp_local[k[0]] = i\n",
    "emp_local_udf = udf(lambda x: emp_local[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f26b6177-0619-4882-a0bc-02e044b1ca05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+\n|experience_level_id|experience_level|\n+-------------------+----------------+\n|                  2|              EN|\n|                  1|              MI|\n|                  3|              SE|\n|                  0|              EX|\n+-------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('experience_level_id',exper_udf(col('experience_level')))\n",
    "exp_level = df.select('experience_level_id','experience_level').distinct()\n",
    "exp_level.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d38123-7d83-4443-90e6-801b62295154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n|employment_type_id|employment_type|\n+------------------+---------------+\n|                 1|             PT|\n|                 0|             FT|\n|                 3|             FL|\n|                 2|             CT|\n+------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('employment_type_id',emp_udf(col('employment_type')))\n",
    "emp_type = df.select('employment_type_id','employment_type').distinct()\n",
    "emp_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fca0029-a681-4fc3-b4bb-464c171a833f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n|job_title_id|           job_title|\n+------------+--------------------+\n|          33|Business Intellig...|\n|          35|Applied Machine L...|\n|          72|        AI Developer|\n|          61|  Analytics Engineer|\n|           2|        Data Modeler|\n|          62|   Research Engineer|\n|          23|Principal Data Sc...|\n|          68|Data Analytics Ma...|\n|          60|   Applied Scientist|\n|          75|     Data Strategist|\n|          46|      Data Scientist|\n|          28|Machine Learning ...|\n|          83|      Data Architect|\n|          65|Business Data Ana...|\n|          74|Data Quality Analyst|\n|          92|Compliance Data A...|\n|          39|  Research Scientist|\n|          71|Computer Vision E...|\n|          90|       Data Engineer|\n|          58|         ML Engineer|\n+------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('job_title_id',jb_udf(col('job_title')))\n",
    "jb_tl = df.select('job_title_id','job_title').distinct()\n",
    "jb_tl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8398aa7-6a09-4428-a2cc-0f9bf2060963",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+\n|salary_currency_id|salary_currency|\n+------------------+---------------+\n|                 4|            BRL|\n|                18|            USD|\n|                15|            CLP|\n|                 1|            HUF|\n|                12|            JPY|\n|                 5|            CZK|\n|                 2|            GBP|\n|                19|            SGD|\n|                17|            PLN|\n|                 3|            CHF|\n|                 8|            EUR|\n|                13|            HKD|\n|                10|            ILS|\n|                11|            AUD|\n|                 6|            TRY|\n|                16|            MXN|\n|                14|            INR|\n|                 0|            DKK|\n|                 9|            THB|\n|                 7|            CAD|\n+------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('salary_currency_id',sal_udf(col('salary_currency')))\n",
    "sal_currency = df.select('salary_currency_id','salary_currency').distinct()\n",
    "sal_currency.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "383ab851-e9e6-4d34-ac72-763da9f02c53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+\n|company_location_id|company_location|\n+-------------------+----------------+\n|                 65|              NG|\n|                  2|              FI|\n|                 66|              CF|\n|                 19|              GH|\n|                 31|              DE|\n|                 43|              CH|\n|                 34|              IL|\n|                 59|              IE|\n|                 40|              IN|\n|                  5|              NL|\n|                 20|              HK|\n|                 48|              SE|\n|                 42|              FR|\n|                 64|              CO|\n|                 26|              GB|\n|                 23|              AU|\n|                 37|              US|\n|                 25|              CA|\n|                  3|              UA|\n|                 32|              ES|\n+-------------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('company_location_id',local_udf(col('company_location')))\n",
    "company_location = df.select('company_location_id','company_location').distinct()\n",
    "company_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdaff96a-0673-420e-83e3-23c82bbc2f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n|employee_residence_id|employee_residence|\n+---------------------+------------------+\n|                    2|                FI|\n|                   18|                GH|\n|                   31|                DE|\n|                   72|                CF|\n|                   12|                AT|\n|                   43|                CH|\n|                   34|                IL|\n|                   40|                IN|\n|                    5|                NL|\n|                   42|                FR|\n|                   26|                GB|\n|                   19|                HK|\n|                   69|                CO|\n|                   24|                CA|\n|                   37|                US|\n|                   22|                AU|\n|                    3|                UA|\n|                   70|                NG|\n|                   63|                IE|\n|                   32|                ES|\n+---------------------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('employee_residence_id',emp_local_udf(col('employee_residence')))\n",
    "emp_residence = df.select('employee_residence_id','employee_residence').distinct()\n",
    "emp_residence.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a87315cf-f92f-4cd3-ba52-3ae0ee062ff0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols = (\"employee_residence\",\"company_location\",\"salary_currency\",'job_title','employment_type','experience_level')\n",
    "\n",
    "df = df.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d33353-4e38-4c70-b129-008d9cf23ae6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdbc:sqlserver://rajdep561.database.windows.net:1433;database=eda;user=rajdep561@rajdep561;password=1@B3ngal1;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\n"
     ]
    }
   ],
   "source": [
    "url_jdbc = f\"jdbc:sqlserver://rajdep561.database.windows.net:1433;database=eda;user=;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "print(url_jdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b823085-ae35-4226-8c7a-a5b3a841ed5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "company_location.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"company_location\").save()\n",
    "\n",
    "\n",
    "emp_residence.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"employee_residence\").save()\n",
    "\n",
    "\n",
    "sal_currency.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"salary_currency\").save()\n",
    "\n",
    "jb_tl.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"job_title\").save()\n",
    "\n",
    "\n",
    "emp_type.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"employment_type\").save()\n",
    "\n",
    "exp_level.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"experience_level\").save()\n",
    "\n",
    "\n",
    "df.write\\\n",
    "    .mode(\"overwrite\").format(\"jdbc\")\\\n",
    "    .option(\"url\", url_jdbc)\\\n",
    "    .option(\"dbtable\", \"fact_ds\").save()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data scientist salary analysis 2023",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
